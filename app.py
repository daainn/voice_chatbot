import streamlit as st
from openai_api import stt, ask_gpt, tts
from audio_recorder_streamlit import audio_recorder
from streamlit_chat import message
import time
import tempfile
import base64
import openai
import os

# Streamlit UI ì„¤ì •
st.set_page_config(layout="wide")  # í™”ë©´ì„ ë„“ê²Œ ì‚¬ìš©
st.markdown(
    """
    <style>
        .center-title {
            text-align: center;
            font-size: 36px;
            font-weight: bold;
            color: #333333;
        }
    </style>
    """,
    unsafe_allow_html=True
)

# ì œëª© ì¶œë ¥
st.markdown('<h1 class="center-title">ğŸ™ GPTì™€ í‹°íƒ€ì„ ğŸ¥¤</h1>', unsafe_allow_html=True)

 # êµ¬ë¶„ì„  ì¶”ê°€
st.markdown("---")

# ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
if st.sidebar.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
    st.session_state.chat_history = []
    st.success("âœ… ì±„íŒ… ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")


# í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •
col1, col2 = st.columns([1, 2])  # ì™¼ìª½(1) / ì˜¤ë¥¸ìª½(2) ë¹„ìœ¨ ì„¤ì •

with col1:
    # ì¸ê³µì§€ëŠ¥ ì´ë¯¸ì§€ ì¶”ê°€
    st.image("https://files.oaiusercontent.com/file-B4t5etLy4wTMjcDHXYBFsT?se=2025-03-05T06%3A16%3A06Z&sp=r&sv=2024-08-04&sr=b&rscc=max-age%3D604800%2C%20immutable%2C%20private&rscd=attachment%3B%20filename%3D51583c76-cd30-4c5c-9d4e-cdf38b1d9a26.webp&sig=aUymPbrYfGvGvsD2J65uOYYRPfmqgP6XOsmbvG2h%2BLg%3D", width=500)
    
    # ì˜¤ë””ì˜¤ ë…¹ìŒ ë²„íŠ¼ í‘œì‹œ (Click to record)
    st.info("ğŸ¤ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§í•´ì£¼ì„¸ìš”!")
    audio_data = audio_recorder("ğŸ¤ Click to record")

    if audio_data:
        st.success("âœ… ë…¹ìŒ ì™„ë£Œ! ì§ˆë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")

        # STT ë³€í™˜ ì‹¤í–‰ (íŒŒì¼ ê²½ë¡œ ì „ë‹¬)
        recognized_text = stt(audio_data)

        # GPT ë‹µë³€ ìƒì„± ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
        with st.spinner("ğŸ¤– ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
            response_text = ask_gpt(recognized_text)

        # GPT ë‹µë³€ í‘œì‹œ
        st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")

        # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸
        st.session_state.chat_history.append({"role": "user", "content": recognized_text})
        st.session_state.chat_history.append({"role": "assistant", "content": response_text})

    #    # GPT ë‹µë³€ ìƒì„± í›„ ìŒì„± ë³€í™˜
    #     audio_path = tts(response_text)  # ìŒì„± íŒŒì¼ ìƒì„±
    #     st.audio(audio_path, format="audio/mp3")  # Streamlitì—ì„œ ì¬ìƒ
        # GPT ì‘ë‹µ ìƒì„± í›„ ìŒì„± ë³€í™˜
        audio_tag = tts(response_text)
        st.markdown(audio_tag, unsafe_allow_html=True)


with col2:
    # ì„¸ì…˜ ìƒíƒœì— ì±„íŒ… ê¸°ë¡ ì €ì¥
    if "chat_history" not in st.session_state:
        st.session_state.chat_history = []
    
   
    
    # ì§ˆë¬¸ ë° ì‘ë‹µ ì¶œë ¥
    if st.session_state.chat_history:
        for i, chat in enumerate(st.session_state.chat_history):
            message(chat["content"], is_user=(chat["role"] == "user"), key=str(i))




# # Streamlit UI
# st.set_page_config(layout="wide")  # í™”ë©´ì„ ë„“ê²Œ ì‚¬ìš©
# st.title("ğŸ™ GPTì™€ í‹°íƒ€ì„ ğŸ¥¤")

# # ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™” ë²„íŠ¼
# if st.sidebar.button("ğŸ—‘ï¸ ì±„íŒ… ê¸°ë¡ ì´ˆê¸°í™”"):
#     st.session_state.chat_history = []
#     st.success("âœ… ì±„íŒ… ê¸°ë¡ì´ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤!")

# # í˜ì´ì§€ ë ˆì´ì•„ì›ƒ ì„¤ì •
# col1, col2 = st.columns([1, 2])  # ì™¼ìª½(1) / ì˜¤ë¥¸ìª½(2) ë¹„ìœ¨ ì„¤ì •

# with col1:
#     # ì¸ê³µì§€ëŠ¥ ì´ë¯¸ì§€ ì¶”ê°€
#     st.image("https://www.k-health.com/news/photo/202306/65884_71441_1839.jpg", width=300)
    
#     # ì˜¤ë””ì˜¤ ë…¹ìŒ ë²„íŠ¼ í‘œì‹œ (Click to record)
#     st.info("ğŸ¤ ë²„íŠ¼ì„ í´ë¦­í•˜ê³  ë§í•œ í›„ ë‹¤ì‹œ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ ì§ˆë¬¸ì´ ìƒì„±ë©ë‹ˆë‹¤.")
#     audio_data = audio_recorder("ğŸ¤ Click to record")

#     if audio_data:
#         st.success("âœ… ë…¹ìŒ ì™„ë£Œ! ì§ˆë¬¸ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤...")

#         # STT ë³€í™˜ ì‹¤í–‰ (íŒŒì¼ ê²½ë¡œ ì „ë‹¬)
#         recognized_text = stt(audio_data)

#         # GPT ë‹µë³€ ìƒì„± ì¤‘ ë©”ì‹œì§€ í‘œì‹œ
#         with st.spinner("ğŸ¤– ë‹µë³€ì„ ìƒì„±í•˜ëŠ” ì¤‘..."):
#             response_text = ask_gpt(recognized_text)

#         # GPT-4oë¡œ ì§ˆë¬¸ í›„ ê²°ê³¼ í‘œì‹œ
#         st.success("âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ!")

#         # ì±„íŒ… ê¸°ë¡ ì—…ë°ì´íŠ¸
#         st.session_state.chat_history.append({"role": "user", "content": recognized_text})
#         st.session_state.chat_history.append({"role": "assistant", "content": response_text})

#         # # TTSë¡œ GPT ì‘ë‹µ ìŒì„± ì¶œë ¥
#         # audio_tag = tts(response_text)

# with col2:
#     # ì„¸ì…˜ ìƒíƒœì— ì±„íŒ… ê¸°ë¡ ì €ì¥
#     if "chat_history" not in st.session_state:
#         st.session_state.chat_history = []
    
#     # êµ¬ë¶„ì„  ì¶”ê°€
#     st.markdown("---")
    
#     # ì§ˆë¬¸ ë° ì‘ë‹µ ì¶œë ¥
#     if st.session_state.chat_history:
#         for i, chat in enumerate(st.session_state.chat_history):
#             message(chat["content"], is_user=(chat["role"] == "user"), key=str(i))
